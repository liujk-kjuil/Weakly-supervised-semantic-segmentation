2025-01-16 21:34:59,993 - Arguments:
2025-01-16 21:34:59,994 - batch_size: 64
2025-01-16 21:34:59,994 - max_epoches: 20
2025-01-16 21:34:59,994 - network: network.resnet38_cls
2025-01-16 21:34:59,994 - lr: 0.007
2025-01-16 21:34:59,994 - num_workers: 10
2025-01-16 21:34:59,994 - wt_dec: 0.0005
2025-01-16 21:34:59,994 - session_name: Stage 1
2025-01-16 21:34:59,994 - env_name: PDA
2025-01-16 21:34:59,994 - model_name: PDA
2025-01-16 21:34:59,994 - n_class: 4
2025-01-16 21:34:59,994 - weights: init_weights/ilsvrc-cls_rna-a1_cls1000_ep-0001.params
2025-01-16 21:34:59,994 - trainroot: datasets/LUAD-HistoSeg/train/
2025-01-16 21:34:59,994 - testroot: datasets/LUAD-HistoSeg/test/
2025-01-16 21:34:59,994 - save_folder: checkpoints/
2025-01-16 21:34:59,994 - init_gama: 1
2025-01-16 21:34:59,994 - dataset: luad
2025-01-16 21:34:59,994 - log_dir: logs/stage1/luad/exp12
2025-01-16 21:34:59,994 - ----------
2025-01-16 21:35:06,301 - Session started:
2025-01-16 21:35:06,301 - Thu Jan 16 21:35:06 2025
2025-01-16 21:36:13,381 - Epoch: 0
2025-01-16 21:36:13,381 - Iter:  100/ 5200
2025-01-16 21:36:13,381 - Loss:0.3286
2025-01-16 21:36:13,381 - avg_ep_EM:0.5502
2025-01-16 21:36:13,381 - avg_ep_acc:0.7502
2025-01-16 21:36:13,381 - lr: 0.006880
2025-01-16 21:36:13,381 - Fin:Thu Jan 16 22:33:14 2025
2025-01-16 21:36:13,381 - ----------
2025-01-16 21:37:19,086 - Epoch: 0
2025-01-16 21:37:19,087 - Iter:  200/ 5200
2025-01-16 21:37:19,087 - Loss:0.2555
2025-01-16 21:37:19,087 - avg_ep_EM:0.6263
2025-01-16 21:37:19,087 - avg_ep_acc:0.8021
2025-01-16 21:37:19,087 - lr: 0.006758
2025-01-16 21:37:19,087 - Fin:Thu Jan 16 22:32:38 2025
2025-01-16 21:37:19,087 - ----------
2025-01-16 21:37:58,658 - Gama of progressive dropout attention is: 0.98000000
2025-01-16 21:38:26,717 - Epoch: 1
2025-01-16 21:38:26,717 - Iter:  300/ 5200
2025-01-16 21:38:26,717 - Loss:0.2278
2025-01-16 21:38:26,717 - avg_ep_EM:0.6669
2025-01-16 21:38:26,717 - avg_ep_acc:0.8298
2025-01-16 21:38:26,718 - lr: 0.006637
2025-01-16 21:38:26,718 - Fin:Thu Jan 16 22:33:00 2025
2025-01-16 21:38:26,718 - ----------
2025-01-16 21:39:32,585 - Epoch: 1
2025-01-16 21:39:32,585 - Iter:  400/ 5200
2025-01-16 21:39:32,585 - Loss:0.2068
2025-01-16 21:39:32,585 - avg_ep_EM:0.7133
2025-01-16 21:39:32,585 - avg_ep_acc:0.8574
2025-01-16 21:39:32,585 - lr: 0.006515
2025-01-16 21:39:32,585 - Fin:Thu Jan 16 22:32:47 2025
2025-01-16 21:39:32,585 - ----------
2025-01-16 21:40:38,717 - Epoch: 1
2025-01-16 21:40:38,717 - Iter:  500/ 5200
2025-01-16 21:40:38,717 - Loss:0.1924
2025-01-16 21:40:38,718 - avg_ep_EM:0.7241
2025-01-16 21:40:38,718 - avg_ep_acc:0.8641
2025-01-16 21:40:38,718 - lr: 0.006392
2025-01-16 21:40:38,718 - Fin:Thu Jan 16 22:32:43 2025
2025-01-16 21:40:38,718 - ----------
2025-01-16 21:40:52,136 - Gama of progressive dropout attention is: 0.96040000
2025-01-16 21:41:46,096 - Epoch: 2
2025-01-16 21:41:46,097 - Iter:  600/ 5200
2025-01-16 21:41:46,097 - Loss:0.1850
2025-01-16 21:41:46,097 - avg_ep_EM:0.7522
2025-01-16 21:41:46,097 - avg_ep_acc:0.8815
2025-01-16 21:41:46,097 - lr: 0.006270
2025-01-16 21:41:46,097 - Fin:Thu Jan 16 22:32:51 2025
2025-01-16 21:41:46,097 - ----------
2025-01-16 21:42:51,943 - Epoch: 2
2025-01-16 21:42:51,943 - Iter:  700/ 5200
2025-01-16 21:42:51,943 - Loss:0.1778
2025-01-16 21:42:51,943 - avg_ep_EM:0.7555
2025-01-16 21:42:51,943 - avg_ep_acc:0.8822
2025-01-16 21:42:51,944 - lr: 0.006147
2025-01-16 21:42:51,944 - Fin:Thu Jan 16 22:32:45 2025
2025-01-16 21:42:51,944 - ----------
2025-01-16 21:43:45,014 - Gama of progressive dropout attention is: 0.94119200
2025-01-16 21:44:00,233 - Epoch: 3
2025-01-16 21:44:00,234 - Iter:  800/ 5200
2025-01-16 21:44:00,234 - Loss:0.1950
2025-01-16 21:44:00,234 - avg_ep_EM:0.7476
2025-01-16 21:44:00,234 - avg_ep_acc:0.8778
2025-01-16 21:44:00,234 - lr: 0.006024
2025-01-16 21:44:00,234 - Fin:Thu Jan 16 22:32:56 2025
2025-01-16 21:44:00,234 - ----------
2025-01-16 21:45:09,707 - Epoch: 3
2025-01-16 21:45:09,707 - Iter:  900/ 5200
2025-01-16 21:45:09,707 - Loss:0.1815
2025-01-16 21:45:09,707 - avg_ep_EM:0.7318
2025-01-16 21:45:09,707 - avg_ep_acc:0.8701
2025-01-16 21:45:09,707 - lr: 0.005901
2025-01-16 21:45:09,707 - Fin:Thu Jan 16 22:33:12 2025
2025-01-16 21:45:09,707 - ----------
2025-01-16 21:46:19,039 - Epoch: 3
2025-01-16 21:46:19,039 - Iter: 1000/ 5200
2025-01-16 21:46:19,039 - Loss:0.1719
2025-01-16 21:46:19,039 - avg_ep_EM:0.7608
2025-01-16 21:46:19,039 - avg_ep_acc:0.8845
2025-01-16 21:46:19,039 - lr: 0.005777
2025-01-16 21:46:19,039 - Fin:Thu Jan 16 22:33:24 2025
2025-01-16 21:46:19,039 - ----------
2025-01-16 21:46:46,679 - Gama of progressive dropout attention is: 0.92236816
2025-01-16 21:47:29,683 - Epoch: 4
2025-01-16 21:47:29,683 - Iter: 1100/ 5200
2025-01-16 21:47:29,683 - Loss:0.1603
2025-01-16 21:47:29,683 - avg_ep_EM:0.7912
2025-01-16 21:47:29,683 - avg_ep_acc:0.9002
2025-01-16 21:47:29,683 - lr: 0.005653
2025-01-16 21:47:29,683 - Fin:Thu Jan 16 22:33:40 2025
2025-01-16 21:47:29,683 - ----------
2025-01-16 21:48:39,011 - Epoch: 4
2025-01-16 21:48:39,012 - Iter: 1200/ 5200
2025-01-16 21:48:39,012 - Loss:0.1539
2025-01-16 21:48:39,012 - avg_ep_EM:0.8055
2025-01-16 21:48:39,012 - avg_ep_acc:0.9078
2025-01-16 21:48:39,012 - lr: 0.005529
2025-01-16 21:48:39,012 - Fin:Thu Jan 16 22:33:48 2025
2025-01-16 21:48:39,012 - ----------
2025-01-16 21:49:47,693 - Epoch: 4
2025-01-16 21:49:47,693 - Iter: 1300/ 5200
2025-01-16 21:49:47,693 - Loss:0.1509
2025-01-16 21:49:47,694 - avg_ep_EM:0.8008
2025-01-16 21:49:47,694 - avg_ep_acc:0.9058
2025-01-16 21:49:47,694 - lr: 0.005404
2025-01-16 21:49:47,694 - Fin:Thu Jan 16 22:33:51 2025
2025-01-16 21:49:47,694 - ----------
2025-01-16 21:49:47,801 - Gama of progressive dropout attention is: 0.90392080
2025-01-16 21:50:58,388 - Epoch: 5
2025-01-16 21:50:58,389 - Iter: 1400/ 5200
2025-01-16 21:50:58,389 - Loss:0.1455
2025-01-16 21:50:58,389 - avg_ep_EM:0.8078
2025-01-16 21:50:58,389 - avg_ep_acc:0.9095
2025-01-16 21:50:58,389 - lr: 0.005280
2025-01-16 21:50:58,389 - Fin:Thu Jan 16 22:34:02 2025
2025-01-16 21:50:58,389 - ----------
2025-01-16 21:52:07,887 - Epoch: 5
2025-01-16 21:52:07,887 - Iter: 1500/ 5200
2025-01-16 21:52:07,887 - Loss:0.1477
2025-01-16 21:52:07,888 - avg_ep_EM:0.8049
2025-01-16 21:52:07,888 - avg_ep_acc:0.9076
2025-01-16 21:52:07,888 - lr: 0.005154
2025-01-16 21:52:07,888 - Fin:Thu Jan 16 22:34:07 2025
2025-01-16 21:52:07,888 - ----------
2025-01-16 21:52:49,436 - Gama of progressive dropout attention is: 0.88584238
2025-01-16 21:53:18,986 - Epoch: 6
2025-01-16 21:53:18,986 - Iter: 1600/ 5200
2025-01-16 21:53:18,986 - Loss:0.1395
2025-01-16 21:53:18,986 - avg_ep_EM:0.8091
2025-01-16 21:53:18,986 - avg_ep_acc:0.9103
2025-01-16 21:53:18,986 - lr: 0.005029
2025-01-16 21:53:18,986 - Fin:Thu Jan 16 22:34:17 2025
2025-01-16 21:53:18,986 - ----------
2025-01-16 21:54:28,101 - Epoch: 6
2025-01-16 21:54:28,101 - Iter: 1700/ 5200
2025-01-16 21:54:28,102 - Loss:0.1363
2025-01-16 21:54:28,102 - avg_ep_EM:0.8189
2025-01-16 21:54:28,102 - avg_ep_acc:0.9157
2025-01-16 21:54:28,102 - lr: 0.004903
2025-01-16 21:54:28,102 - Fin:Thu Jan 16 22:34:20 2025
2025-01-16 21:54:28,102 - ----------
2025-01-16 21:55:37,206 - Epoch: 6
2025-01-16 21:55:37,206 - Iter: 1800/ 5200
2025-01-16 21:55:37,206 - Loss:0.1323
2025-01-16 21:55:37,206 - avg_ep_EM:0.8218
2025-01-16 21:55:37,206 - avg_ep_acc:0.9166
2025-01-16 21:55:37,206 - lr: 0.004777
2025-01-16 21:55:37,206 - Fin:Thu Jan 16 22:34:22 2025
2025-01-16 21:55:37,206 - ----------
2025-01-16 21:55:51,256 - Gama of progressive dropout attention is: 0.86812553
2025-01-16 21:56:48,022 - Epoch: 7
2025-01-16 21:56:48,022 - Iter: 1900/ 5200
2025-01-16 21:56:48,022 - Loss:0.1334
2025-01-16 21:56:48,022 - avg_ep_EM:0.8224
2025-01-16 21:56:48,022 - avg_ep_acc:0.9158
2025-01-16 21:56:48,022 - lr: 0.004650
2025-01-16 21:56:48,022 - Fin:Thu Jan 16 22:34:28 2025
2025-01-16 21:56:48,022 - ----------
2025-01-16 21:57:57,015 - Epoch: 7
2025-01-16 21:57:57,016 - Iter: 2000/ 5200
2025-01-16 21:57:57,016 - Loss:0.1284
2025-01-16 21:57:57,016 - avg_ep_EM:0.8240
2025-01-16 21:57:57,016 - avg_ep_acc:0.9172
2025-01-16 21:57:57,016 - lr: 0.004523
2025-01-16 21:57:57,016 - Fin:Thu Jan 16 22:34:30 2025
2025-01-16 21:57:57,016 - ----------
2025-01-16 21:58:52,496 - Gama of progressive dropout attention is: 0.85076302
2025-01-16 21:59:07,864 - Epoch: 8
2025-01-16 21:59:07,864 - Iter: 2100/ 5200
2025-01-16 21:59:07,864 - Loss:0.1294
2025-01-16 21:59:07,864 - avg_ep_EM:0.8289
2025-01-16 21:59:07,864 - avg_ep_acc:0.9197
2025-01-16 21:59:07,864 - lr: 0.004396
2025-01-16 21:59:07,864 - Fin:Thu Jan 16 22:34:35 2025
2025-01-16 21:59:07,864 - ----------
2025-01-16 22:00:17,009 - Epoch: 8
2025-01-16 22:00:17,009 - Iter: 2200/ 5200
2025-01-16 22:00:17,010 - Loss:0.1257
2025-01-16 22:00:17,010 - avg_ep_EM:0.8349
2025-01-16 22:00:17,010 - avg_ep_acc:0.9225
2025-01-16 22:00:17,010 - lr: 0.004268
2025-01-16 22:00:17,010 - Fin:Thu Jan 16 22:34:37 2025
2025-01-16 22:00:17,010 - ----------
2025-01-16 22:01:26,023 - Epoch: 8
2025-01-16 22:01:26,023 - Iter: 2300/ 5200
2025-01-16 22:01:26,023 - Loss:0.1251
2025-01-16 22:01:26,023 - avg_ep_EM:0.8348
2025-01-16 22:01:26,023 - avg_ep_acc:0.9226
2025-01-16 22:01:26,023 - lr: 0.004140
2025-01-16 22:01:26,023 - Fin:Thu Jan 16 22:34:37 2025
2025-01-16 22:01:26,023 - ----------
2025-01-16 22:01:53,980 - Gama of progressive dropout attention is: 0.83374776
2025-01-16 22:02:37,101 - Epoch: 9
2025-01-16 22:02:37,101 - Iter: 2400/ 5200
2025-01-16 22:02:37,101 - Loss:0.1174
2025-01-16 22:02:37,101 - avg_ep_EM:0.8419
2025-01-16 22:02:37,101 - avg_ep_acc:0.9259
2025-01-16 22:02:37,101 - lr: 0.004011
2025-01-16 22:02:37,101 - Fin:Thu Jan 16 22:34:43 2025
2025-01-16 22:02:37,101 - ----------
2025-01-16 22:03:46,162 - Epoch: 9
2025-01-16 22:03:46,163 - Iter: 2500/ 5200
2025-01-16 22:03:46,163 - Loss:0.1217
2025-01-16 22:03:46,163 - avg_ep_EM:0.8447
2025-01-16 22:03:46,163 - avg_ep_acc:0.9275
2025-01-16 22:03:46,163 - lr: 0.003882
2025-01-16 22:03:46,163 - Fin:Thu Jan 16 22:34:43 2025
2025-01-16 22:03:46,163 - ----------
2025-01-16 22:04:55,786 - Epoch: 9
2025-01-16 22:04:55,787 - Iter: 2600/ 5200
2025-01-16 22:04:55,787 - Loss:0.1273
2025-01-16 22:04:55,787 - avg_ep_EM:0.8413
2025-01-16 22:04:55,787 - avg_ep_acc:0.9262
2025-01-16 22:04:55,787 - lr: 0.003753
2025-01-16 22:04:55,787 - Fin:Thu Jan 16 22:34:45 2025
2025-01-16 22:04:55,787 - ----------
2025-01-16 22:04:55,932 - Gama of progressive dropout attention is: 0.81707281
2025-01-16 22:06:06,174 - Epoch:10
2025-01-16 22:06:06,174 - Iter: 2700/ 5200
2025-01-16 22:06:06,174 - Loss:0.1132
2025-01-16 22:06:06,175 - avg_ep_EM:0.8510
2025-01-16 22:06:06,175 - avg_ep_acc:0.9307
2025-01-16 22:06:06,175 - lr: 0.003622
2025-01-16 22:06:06,175 - Fin:Thu Jan 16 22:34:48 2025
2025-01-16 22:06:06,175 - ----------
2025-01-16 22:07:15,518 - Epoch:10
2025-01-16 22:07:15,519 - Iter: 2800/ 5200
2025-01-16 22:07:15,519 - Loss:0.1245
2025-01-16 22:07:15,519 - avg_ep_EM:0.8425
2025-01-16 22:07:15,519 - avg_ep_acc:0.9272
2025-01-16 22:07:15,519 - lr: 0.003492
2025-01-16 22:07:15,519 - Fin:Thu Jan 16 22:34:49 2025
2025-01-16 22:07:15,519 - ----------
2025-01-16 22:07:57,160 - Gama of progressive dropout attention is: 0.80073135
2025-01-16 22:08:26,303 - Epoch:11
2025-01-16 22:08:26,303 - Iter: 2900/ 5200
2025-01-16 22:08:26,303 - Loss:0.1186
2025-01-16 22:08:26,303 - avg_ep_EM:0.8402
2025-01-16 22:08:26,303 - avg_ep_acc:0.9258
2025-01-16 22:08:26,303 - lr: 0.003361
2025-01-16 22:08:26,303 - Fin:Thu Jan 16 22:34:52 2025
2025-01-16 22:08:26,303 - ----------
2025-01-16 22:09:35,441 - Epoch:11
2025-01-16 22:09:35,441 - Iter: 3000/ 5200
2025-01-16 22:09:35,441 - Loss:0.1110
2025-01-16 22:09:35,441 - avg_ep_EM:0.8461
2025-01-16 22:09:35,441 - avg_ep_acc:0.9283
2025-01-16 22:09:35,441 - lr: 0.003229
2025-01-16 22:09:35,441 - Fin:Thu Jan 16 22:34:52 2025
2025-01-16 22:09:35,441 - ----------
2025-01-16 22:10:44,614 - Epoch:11
2025-01-16 22:10:44,614 - Iter: 3100/ 5200
2025-01-16 22:10:44,614 - Loss:0.1139
2025-01-16 22:10:44,614 - avg_ep_EM:0.8505
2025-01-16 22:10:44,614 - avg_ep_acc:0.9303
2025-01-16 22:10:44,614 - lr: 0.003097
2025-01-16 22:10:44,614 - Fin:Thu Jan 16 22:34:53 2025
2025-01-16 22:10:44,614 - ----------
2025-01-16 22:10:58,476 - Gama of progressive dropout attention is: 0.78471672
2025-01-16 22:11:55,203 - Epoch:12
2025-01-16 22:11:55,204 - Iter: 3200/ 5200
2025-01-16 22:11:55,204 - Loss:0.1123
2025-01-16 22:11:55,204 - avg_ep_EM:0.8594
2025-01-16 22:11:55,204 - avg_ep_acc:0.9347
2025-01-16 22:11:55,204 - lr: 0.002964
2025-01-16 22:11:55,204 - Fin:Thu Jan 16 22:34:55 2025
2025-01-16 22:11:55,204 - ----------
2025-01-16 22:13:04,265 - Epoch:12
2025-01-16 22:13:04,265 - Iter: 3300/ 5200
2025-01-16 22:13:04,265 - Loss:0.1133
2025-01-16 22:13:04,265 - avg_ep_EM:0.8542
2025-01-16 22:13:04,265 - avg_ep_acc:0.9323
2025-01-16 22:13:04,265 - lr: 0.002830
2025-01-16 22:13:04,265 - Fin:Thu Jan 16 22:34:55 2025
2025-01-16 22:13:04,265 - ----------
2025-01-16 22:13:59,831 - Gama of progressive dropout attention is: 0.76902239
2025-01-16 22:14:15,208 - Epoch:13
2025-01-16 22:14:15,209 - Iter: 3400/ 5200
2025-01-16 22:14:15,209 - Loss:0.1136
2025-01-16 22:14:15,209 - avg_ep_EM:0.8538
2025-01-16 22:14:15,209 - avg_ep_acc:0.9321
2025-01-16 22:14:15,209 - lr: 0.002696
2025-01-16 22:14:15,209 - Fin:Thu Jan 16 22:34:58 2025
2025-01-16 22:14:15,209 - ----------
2025-01-16 22:15:24,319 - Epoch:13
2025-01-16 22:15:24,320 - Iter: 3500/ 5200
2025-01-16 22:15:24,320 - Loss:0.1106
2025-01-16 22:15:24,320 - avg_ep_EM:0.8578
2025-01-16 22:15:24,320 - avg_ep_acc:0.9336
2025-01-16 22:15:24,320 - lr: 0.002561
2025-01-16 22:15:24,320 - Fin:Thu Jan 16 22:34:58 2025
2025-01-16 22:15:24,320 - ----------
2025-01-16 22:16:33,498 - Epoch:13
2025-01-16 22:16:33,498 - Iter: 3600/ 5200
2025-01-16 22:16:33,498 - Loss:0.1132
2025-01-16 22:16:33,498 - avg_ep_EM:0.8544
2025-01-16 22:16:33,498 - avg_ep_acc:0.9321
2025-01-16 22:16:33,499 - lr: 0.002425
2025-01-16 22:16:33,499 - Fin:Thu Jan 16 22:34:58 2025
2025-01-16 22:16:33,499 - ----------
2025-01-16 22:17:01,279 - Gama of progressive dropout attention is: 0.75364194
2025-01-16 22:17:44,119 - Epoch:14
2025-01-16 22:17:44,120 - Iter: 3700/ 5200
2025-01-16 22:17:44,120 - Loss:0.1084
2025-01-16 22:17:44,120 - avg_ep_EM:0.8568
2025-01-16 22:17:44,120 - avg_ep_acc:0.9332
2025-01-16 22:17:44,120 - lr: 0.002288
2025-01-16 22:17:44,120 - Fin:Thu Jan 16 22:35:01 2025
2025-01-16 22:17:44,120 - ----------
2025-01-16 22:18:53,007 - Epoch:14
2025-01-16 22:18:53,007 - Iter: 3800/ 5200
2025-01-16 22:18:53,007 - Loss:0.1116
2025-01-16 22:18:53,007 - avg_ep_EM:0.8535
2025-01-16 22:18:53,007 - avg_ep_acc:0.9319
2025-01-16 22:18:53,007 - lr: 0.002150
2025-01-16 22:18:53,007 - Fin:Thu Jan 16 22:35:00 2025
2025-01-16 22:18:53,007 - ----------
2025-01-16 22:20:02,229 - Epoch:14
2025-01-16 22:20:02,229 - Iter: 3900/ 5200
2025-01-16 22:20:02,229 - Loss:0.1092
2025-01-16 22:20:02,229 - avg_ep_EM:0.8527
2025-01-16 22:20:02,229 - avg_ep_acc:0.9317
2025-01-16 22:20:02,229 - lr: 0.002012
2025-01-16 22:20:02,230 - Fin:Thu Jan 16 22:35:00 2025
2025-01-16 22:20:02,230 - ----------
2025-01-16 22:20:02,322 - Gama of progressive dropout attention is: 0.73856910
2025-01-16 22:21:12,712 - Epoch:15
2025-01-16 22:21:12,713 - Iter: 4000/ 5200
2025-01-16 22:21:12,713 - Loss:0.1113
2025-01-16 22:21:12,713 - avg_ep_EM:0.8507
2025-01-16 22:21:12,713 - avg_ep_acc:0.9305
2025-01-16 22:21:12,713 - lr: 0.001872
2025-01-16 22:21:12,713 - Fin:Thu Jan 16 22:35:02 2025
2025-01-16 22:21:12,713 - ----------
2025-01-16 22:22:21,612 - Epoch:15
2025-01-16 22:22:21,612 - Iter: 4100/ 5200
2025-01-16 22:22:21,612 - Loss:0.1063
2025-01-16 22:22:21,612 - avg_ep_EM:0.8528
2025-01-16 22:22:21,612 - avg_ep_acc:0.9316
2025-01-16 22:22:21,612 - lr: 0.001731
2025-01-16 22:22:21,612 - Fin:Thu Jan 16 22:35:02 2025
2025-01-16 22:22:21,612 - ----------
2025-01-16 22:23:03,003 - Gama of progressive dropout attention is: 0.72379772
2025-01-16 22:23:32,577 - Epoch:16
2025-01-16 22:23:32,578 - Iter: 4200/ 5200
2025-01-16 22:23:32,578 - Loss:0.1051
2025-01-16 22:23:32,578 - avg_ep_EM:0.8573
2025-01-16 22:23:32,578 - avg_ep_acc:0.9337
2025-01-16 22:23:32,578 - lr: 0.001589
2025-01-16 22:23:32,578 - Fin:Thu Jan 16 22:35:04 2025
2025-01-16 22:23:32,578 - ----------
2025-01-16 22:24:42,059 - Epoch:16
2025-01-16 22:24:42,059 - Iter: 4300/ 5200
2025-01-16 22:24:42,059 - Loss:0.1081
2025-01-16 22:24:42,059 - avg_ep_EM:0.8571
2025-01-16 22:24:42,059 - avg_ep_acc:0.9341
2025-01-16 22:24:42,059 - lr: 0.001445
2025-01-16 22:24:42,059 - Fin:Thu Jan 16 22:35:04 2025
2025-01-16 22:24:42,059 - ----------
2025-01-16 22:25:50,941 - Epoch:16
2025-01-16 22:25:50,942 - Iter: 4400/ 5200
2025-01-16 22:25:50,942 - Loss:0.1047
2025-01-16 22:25:50,942 - avg_ep_EM:0.8601
2025-01-16 22:25:50,942 - avg_ep_acc:0.9354
2025-01-16 22:25:50,942 - lr: 0.001300
2025-01-16 22:25:50,942 - Fin:Thu Jan 16 22:35:04 2025
2025-01-16 22:25:50,942 - ----------
2025-01-16 22:26:04,920 - Gama of progressive dropout attention is: 0.70932177
2025-01-16 22:27:02,037 - Epoch:17
2025-01-16 22:27:02,038 - Iter: 4500/ 5200
2025-01-16 22:27:02,038 - Loss:0.1048
2025-01-16 22:27:02,038 - avg_ep_EM:0.8620
2025-01-16 22:27:02,038 - avg_ep_acc:0.9359
2025-01-16 22:27:02,038 - lr: 0.001153
2025-01-16 22:27:02,038 - Fin:Thu Jan 16 22:35:06 2025
2025-01-16 22:27:02,038 - ----------
2025-01-16 22:28:11,117 - Epoch:17
2025-01-16 22:28:11,118 - Iter: 4600/ 5200
2025-01-16 22:28:11,118 - Loss:0.1034
2025-01-16 22:28:11,118 - avg_ep_EM:0.8636
2025-01-16 22:28:11,118 - avg_ep_acc:0.9367
2025-01-16 22:28:11,118 - lr: 0.001004
2025-01-16 22:28:11,118 - Fin:Thu Jan 16 22:35:06 2025
2025-01-16 22:28:11,118 - ----------
2025-01-16 22:29:06,294 - Gama of progressive dropout attention is: 0.69513533
2025-01-16 22:29:21,585 - Epoch:18
2025-01-16 22:29:21,585 - Iter: 4700/ 5200
2025-01-16 22:29:21,585 - Loss:0.1078
2025-01-16 22:29:21,585 - avg_ep_EM:0.8601
2025-01-16 22:29:21,585 - avg_ep_acc:0.9354
2025-01-16 22:29:21,585 - lr: 0.000852
2025-01-16 22:29:21,585 - Fin:Thu Jan 16 22:35:07 2025
2025-01-16 22:29:21,585 - ----------
2025-01-16 22:30:30,513 - Epoch:18
2025-01-16 22:30:30,513 - Iter: 4800/ 5200
2025-01-16 22:30:30,513 - Loss:0.1031
2025-01-16 22:30:30,513 - avg_ep_EM:0.8612
2025-01-16 22:30:30,513 - avg_ep_acc:0.9355
2025-01-16 22:30:30,513 - lr: 0.000697
2025-01-16 22:30:30,513 - Fin:Thu Jan 16 22:35:07 2025
2025-01-16 22:30:30,513 - ----------
2025-01-16 22:31:39,655 - Epoch:18
2025-01-16 22:31:39,655 - Iter: 4900/ 5200
2025-01-16 22:31:39,655 - Loss:0.1079
2025-01-16 22:31:39,655 - avg_ep_EM:0.8603
2025-01-16 22:31:39,655 - avg_ep_acc:0.9352
2025-01-16 22:31:39,655 - lr: 0.000539
2025-01-16 22:31:39,655 - Fin:Thu Jan 16 22:35:07 2025
2025-01-16 22:31:39,655 - ----------
2025-01-16 22:32:07,417 - Gama of progressive dropout attention is: 0.68123262
2025-01-16 22:32:50,802 - Epoch:19
2025-01-16 22:32:50,802 - Iter: 5000/ 5200
2025-01-16 22:32:50,802 - Loss:0.1025
2025-01-16 22:32:50,802 - avg_ep_EM:0.8549
2025-01-16 22:32:50,802 - avg_ep_acc:0.9321
2025-01-16 22:32:50,802 - lr: 0.000375
2025-01-16 22:32:50,802 - Fin:Thu Jan 16 22:35:09 2025
2025-01-16 22:32:50,802 - ----------
2025-01-16 22:33:59,738 - Epoch:19
2025-01-16 22:33:59,738 - Iter: 5100/ 5200
2025-01-16 22:33:59,738 - Loss:0.1051
2025-01-16 22:33:59,738 - avg_ep_EM:0.8587
2025-01-16 22:33:59,738 - avg_ep_acc:0.9346
2025-01-16 22:33:59,738 - lr: 0.000202
2025-01-16 22:33:59,739 - Fin:Thu Jan 16 22:35:09 2025
2025-01-16 22:33:59,739 - ----------
2025-01-16 22:35:08,689 - Epoch:19
2025-01-16 22:35:08,689 - Iter: 5200/ 5200
2025-01-16 22:35:08,689 - Loss:0.1024
2025-01-16 22:35:08,689 - avg_ep_EM:0.8587
2025-01-16 22:35:08,689 - avg_ep_acc:0.9347
2025-01-16 22:35:08,689 - lr: 0.000003
2025-01-16 22:35:08,689 - Fin:Thu Jan 16 22:35:08 2025
2025-01-16 22:35:08,689 - ----------
2025-01-16 22:35:08,879 - Gama of progressive dropout attention is: 0.66760797
2025-01-16 22:35:11,310 - 0
2025-01-16 22:35:13,500 - 100
2025-01-16 22:35:15,570 - 200
2025-01-16 22:35:17,523 - 300
2025-01-16 22:35:17,912 - ===== Evaluation Scores =====
2025-01-16 22:35:17,912 - Pixel Accuracy: 0.8435
2025-01-16 22:35:17,912 - Mean Accuracy: 0.8480
2025-01-16 22:35:17,912 - Frequency Weighted IoU: 0.7310
2025-01-16 22:35:17,912 - Mean IoU: 0.7450
2025-01-16 22:35:17,912 - ===== Class IoU =====
2025-01-16 22:35:17,912 - Class 0: 0.7495
2025-01-16 22:35:17,912 - Class 1: 0.8007
2025-01-16 22:35:17,912 - Class 2: 0.7353
2025-01-16 22:35:17,912 - Class 3: 0.6944
