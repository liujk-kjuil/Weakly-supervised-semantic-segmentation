2025-01-12 16:08:35,600 - Arguments:
2025-01-12 16:08:35,600 - batch_size: 64
2025-01-12 16:08:35,600 - max_epoches: 20
2025-01-12 16:08:35,601 - network: network.resnet38_cls
2025-01-12 16:08:35,601 - lr: 0.005
2025-01-12 16:08:35,601 - num_workers: 10
2025-01-12 16:08:35,601 - wt_dec: 0.0005
2025-01-12 16:08:35,601 - session_name: Stage 1
2025-01-12 16:08:35,601 - env_name: PDA
2025-01-12 16:08:35,601 - model_name: PDA
2025-01-12 16:08:35,601 - n_class: 4
2025-01-12 16:08:35,601 - weights: init_weights/ilsvrc-cls_rna-a1_cls1000_ep-0001.params
2025-01-12 16:08:35,601 - trainroot: datasets/LUAD-HistoSeg/train/
2025-01-12 16:08:35,601 - testroot: datasets/LUAD-HistoSeg/test/
2025-01-12 16:08:35,601 - save_folder: checkpoints/
2025-01-12 16:08:35,601 - init_gama: 1
2025-01-12 16:08:35,601 - dataset: luad
2025-01-12 16:08:35,601 - log_dir: logs/stage1/exp10
2025-01-12 16:08:35,601 - ----------
2025-01-12 16:08:41,295 - Session started:
2025-01-12 16:08:41,295 - Sun Jan 12 16:08:41 2025
2025-01-12 16:09:49,750 - Epoch: 0
2025-01-12 16:09:49,751 - Iter:  100/ 5200
2025-01-12 16:09:49,751 - Loss:0.3363
2025-01-12 16:09:49,751 - avg_ep_EM:0.5476
2025-01-12 16:09:49,751 - avg_ep_acc:0.7361
2025-01-12 16:09:49,751 - lr: 0.004914
2025-01-12 16:09:49,751 - Fin:Sun Jan 12 17:08:00 2025
2025-01-12 16:09:49,751 - ----------
2025-01-12 16:10:56,375 - Epoch: 0
2025-01-12 16:10:56,376 - Iter:  200/ 5200
2025-01-12 16:10:56,376 - Loss:0.2587
2025-01-12 16:10:56,376 - avg_ep_EM:0.6257
2025-01-12 16:10:56,376 - avg_ep_acc:0.7987
2025-01-12 16:10:56,376 - lr: 0.004827
2025-01-12 16:10:56,376 - Fin:Sun Jan 12 17:07:13 2025
2025-01-12 16:10:56,376 - ----------
2025-01-12 16:11:36,537 - Gama of progressive dropout attention is: 0.98000000
2025-01-12 16:12:05,184 - Epoch: 1
2025-01-12 16:12:05,184 - Iter:  300/ 5200
2025-01-12 16:12:05,184 - Loss:0.2292
2025-01-12 16:12:05,184 - avg_ep_EM:0.6713
2025-01-12 16:12:05,184 - avg_ep_acc:0.8307
2025-01-12 16:12:05,184 - lr: 0.004740
2025-01-12 16:12:05,184 - Fin:Sun Jan 12 17:07:35 2025
2025-01-12 16:12:05,184 - ----------
2025-01-12 16:13:12,064 - Epoch: 1
2025-01-12 16:13:12,064 - Iter:  400/ 5200
2025-01-12 16:13:12,065 - Loss:0.2151
2025-01-12 16:13:12,065 - avg_ep_EM:0.7079
2025-01-12 16:13:12,065 - avg_ep_acc:0.8559
2025-01-12 16:13:12,065 - lr: 0.004653
2025-01-12 16:13:12,065 - Fin:Sun Jan 12 17:07:21 2025
2025-01-12 16:13:12,065 - ----------
2025-01-12 16:14:19,133 - Epoch: 1
2025-01-12 16:14:19,133 - Iter:  500/ 5200
2025-01-12 16:14:19,133 - Loss:0.1926
2025-01-12 16:14:19,133 - avg_ep_EM:0.7196
2025-01-12 16:14:19,133 - avg_ep_acc:0.8621
2025-01-12 16:14:19,133 - lr: 0.004566
2025-01-12 16:14:19,134 - Fin:Sun Jan 12 17:07:14 2025
2025-01-12 16:14:19,134 - ----------
2025-01-12 16:14:32,645 - Gama of progressive dropout attention is: 0.96040000
2025-01-12 16:15:27,988 - Epoch: 2
2025-01-12 16:15:27,988 - Iter:  600/ 5200
2025-01-12 16:15:27,988 - Loss:0.1888
2025-01-12 16:15:27,988 - avg_ep_EM:0.7396
2025-01-12 16:15:27,988 - avg_ep_acc:0.8727
2025-01-12 16:15:27,988 - lr: 0.004479
2025-01-12 16:15:27,989 - Fin:Sun Jan 12 17:07:25 2025
2025-01-12 16:15:27,989 - ----------
2025-01-12 16:16:34,651 - Epoch: 2
2025-01-12 16:16:34,651 - Iter:  700/ 5200
2025-01-12 16:16:34,651 - Loss:0.1842
2025-01-12 16:16:34,651 - avg_ep_EM:0.7497
2025-01-12 16:16:34,651 - avg_ep_acc:0.8784
2025-01-12 16:16:34,651 - lr: 0.004391
2025-01-12 16:16:34,651 - Fin:Sun Jan 12 17:07:17 2025
2025-01-12 16:16:34,651 - ----------
2025-01-12 16:17:28,143 - Gama of progressive dropout attention is: 0.94119200
2025-01-12 16:17:43,900 - Epoch: 3
2025-01-12 16:17:43,900 - Iter:  800/ 5200
2025-01-12 16:17:43,900 - Loss:0.1925
2025-01-12 16:17:43,900 - avg_ep_EM:0.7425
2025-01-12 16:17:43,900 - avg_ep_acc:0.8743
2025-01-12 16:17:43,901 - lr: 0.004303
2025-01-12 16:17:43,901 - Fin:Sun Jan 12 17:07:28 2025
2025-01-12 16:17:43,901 - ----------
2025-01-12 16:18:53,993 - Epoch: 3
2025-01-12 16:18:53,993 - Iter:  900/ 5200
2025-01-12 16:18:53,993 - Loss:0.1806
2025-01-12 16:18:53,993 - avg_ep_EM:0.7517
2025-01-12 16:18:53,993 - avg_ep_acc:0.8801
2025-01-12 16:18:53,993 - lr: 0.004215
2025-01-12 16:18:53,993 - Fin:Sun Jan 12 17:07:41 2025
2025-01-12 16:18:53,993 - ----------
2025-01-12 16:20:03,842 - Epoch: 3
2025-01-12 16:20:03,843 - Iter: 1000/ 5200
2025-01-12 16:20:03,843 - Loss:0.1797
2025-01-12 16:20:03,843 - avg_ep_EM:0.7610
2025-01-12 16:20:03,843 - avg_ep_acc:0.8854
2025-01-12 16:20:03,843 - lr: 0.004127
2025-01-12 16:20:03,843 - Fin:Sun Jan 12 17:07:50 2025
2025-01-12 16:20:03,843 - ----------
2025-01-12 16:20:32,068 - Gama of progressive dropout attention is: 0.92236816
2025-01-12 16:21:16,015 - Epoch: 4
2025-01-12 16:21:16,015 - Iter: 1100/ 5200
2025-01-12 16:21:16,015 - Loss:0.1708
2025-01-12 16:21:16,015 - avg_ep_EM:0.7799
2025-01-12 16:21:16,015 - avg_ep_acc:0.8945
2025-01-12 16:21:16,015 - lr: 0.004038
2025-01-12 16:21:16,015 - Fin:Sun Jan 12 17:08:09 2025
2025-01-12 16:21:16,015 - ----------
2025-01-12 16:22:25,942 - Epoch: 4
2025-01-12 16:22:25,943 - Iter: 1200/ 5200
2025-01-12 16:22:25,943 - Loss:0.1638
2025-01-12 16:22:25,943 - avg_ep_EM:0.7857
2025-01-12 16:22:25,943 - avg_ep_acc:0.8980
2025-01-12 16:22:25,943 - lr: 0.003949
2025-01-12 16:22:25,943 - Fin:Sun Jan 12 17:08:14 2025
2025-01-12 16:22:25,943 - ----------
2025-01-12 16:23:36,143 - Epoch: 4
2025-01-12 16:23:36,143 - Iter: 1300/ 5200
2025-01-12 16:23:36,143 - Loss:0.1503
2025-01-12 16:23:36,143 - avg_ep_EM:0.7879
2025-01-12 16:23:36,143 - avg_ep_acc:0.8995
2025-01-12 16:23:36,143 - lr: 0.003860
2025-01-12 16:23:36,143 - Fin:Sun Jan 12 17:08:20 2025
2025-01-12 16:23:36,143 - ----------
2025-01-12 16:23:36,328 - Gama of progressive dropout attention is: 0.90392080
2025-01-12 16:24:47,773 - Epoch: 5
2025-01-12 16:24:47,773 - Iter: 1400/ 5200
2025-01-12 16:24:47,773 - Loss:0.1529
2025-01-12 16:24:47,773 - avg_ep_EM:0.7941
2025-01-12 16:24:47,773 - avg_ep_acc:0.9027
2025-01-12 16:24:47,773 - lr: 0.003771
2025-01-12 16:24:47,773 - Fin:Sun Jan 12 17:08:31 2025
2025-01-12 16:24:47,773 - ----------
2025-01-12 16:25:57,500 - Epoch: 5
2025-01-12 16:25:57,501 - Iter: 1500/ 5200
2025-01-12 16:25:57,501 - Loss:0.1483
2025-01-12 16:25:57,501 - avg_ep_EM:0.7991
2025-01-12 16:25:57,501 - avg_ep_acc:0.9050
2025-01-12 16:25:57,501 - lr: 0.003682
2025-01-12 16:25:57,501 - Fin:Sun Jan 12 17:08:33 2025
2025-01-12 16:25:57,501 - ----------
2025-01-12 16:26:39,544 - Gama of progressive dropout attention is: 0.88584238
2025-01-12 16:27:09,596 - Epoch: 6
2025-01-12 16:27:09,596 - Iter: 1600/ 5200
2025-01-12 16:27:09,596 - Loss:0.1523
2025-01-12 16:27:09,596 - avg_ep_EM:0.8041
2025-01-12 16:27:09,596 - avg_ep_acc:0.9060
2025-01-12 16:27:09,597 - lr: 0.003592
2025-01-12 16:27:09,597 - Fin:Sun Jan 12 17:08:43 2025
2025-01-12 16:27:09,597 - ----------
2025-01-12 16:28:19,448 - Epoch: 6
2025-01-12 16:28:19,448 - Iter: 1700/ 5200
2025-01-12 16:28:19,449 - Loss:0.1391
2025-01-12 16:28:19,449 - avg_ep_EM:0.8059
2025-01-12 16:28:19,449 - avg_ep_acc:0.9075
2025-01-12 16:28:19,449 - lr: 0.003502
2025-01-12 16:28:19,449 - Fin:Sun Jan 12 17:08:45 2025
2025-01-12 16:28:19,449 - ----------
2025-01-12 16:29:29,382 - Epoch: 6
2025-01-12 16:29:29,383 - Iter: 1800/ 5200
2025-01-12 16:29:29,383 - Loss:0.1422
2025-01-12 16:29:29,383 - avg_ep_EM:0.8100
2025-01-12 16:29:29,383 - avg_ep_acc:0.9106
2025-01-12 16:29:29,383 - lr: 0.003412
2025-01-12 16:29:29,383 - Fin:Sun Jan 12 17:08:46 2025
2025-01-12 16:29:29,383 - ----------
2025-01-12 16:29:43,605 - Gama of progressive dropout attention is: 0.86812553
2025-01-12 16:30:41,417 - Epoch: 7
2025-01-12 16:30:41,417 - Iter: 1900/ 5200
2025-01-12 16:30:41,417 - Loss:0.1340
2025-01-12 16:30:41,417 - avg_ep_EM:0.8193
2025-01-12 16:30:41,417 - avg_ep_acc:0.9164
2025-01-12 16:30:41,417 - lr: 0.003322
2025-01-12 16:30:41,417 - Fin:Sun Jan 12 17:08:54 2025
2025-01-12 16:30:41,417 - ----------
2025-01-12 16:31:51,435 - Epoch: 7
2025-01-12 16:31:51,436 - Iter: 2000/ 5200
2025-01-12 16:31:51,436 - Loss:0.1390
2025-01-12 16:31:51,436 - avg_ep_EM:0.8220
2025-01-12 16:31:51,436 - avg_ep_acc:0.9169
2025-01-12 16:31:51,436 - lr: 0.003231
2025-01-12 16:31:51,436 - Fin:Sun Jan 12 17:08:55 2025
2025-01-12 16:31:51,436 - ----------
2025-01-12 16:32:47,550 - Gama of progressive dropout attention is: 0.85076302
2025-01-12 16:33:03,071 - Epoch: 8
2025-01-12 16:33:03,071 - Iter: 2100/ 5200
2025-01-12 16:33:03,071 - Loss:0.1359
2025-01-12 16:33:03,072 - avg_ep_EM:0.8178
2025-01-12 16:33:03,072 - avg_ep_acc:0.9145
2025-01-12 16:33:03,072 - lr: 0.003140
2025-01-12 16:33:03,072 - Fin:Sun Jan 12 17:09:00 2025
2025-01-12 16:33:03,072 - ----------
2025-01-12 16:34:12,997 - Epoch: 8
2025-01-12 16:34:12,997 - Iter: 2200/ 5200
2025-01-12 16:34:12,997 - Loss:0.1350
2025-01-12 16:34:12,997 - avg_ep_EM:0.8209
2025-01-12 16:34:12,997 - avg_ep_acc:0.9159
2025-01-12 16:34:12,997 - lr: 0.003049
2025-01-12 16:34:12,998 - Fin:Sun Jan 12 17:09:01 2025
2025-01-12 16:34:12,998 - ----------
2025-01-12 16:35:22,667 - Epoch: 8
2025-01-12 16:35:22,667 - Iter: 2300/ 5200
2025-01-12 16:35:22,667 - Loss:0.1276
2025-01-12 16:35:22,667 - avg_ep_EM:0.8225
2025-01-12 16:35:22,667 - avg_ep_acc:0.9175
2025-01-12 16:35:22,667 - lr: 0.002957
2025-01-12 16:35:22,667 - Fin:Sun Jan 12 17:09:01 2025
2025-01-12 16:35:22,667 - ----------
2025-01-12 16:35:50,513 - Gama of progressive dropout attention is: 0.83374776
2025-01-12 16:36:33,497 - Epoch: 9
2025-01-12 16:36:33,497 - Iter: 2400/ 5200
2025-01-12 16:36:33,497 - Loss:0.1272
2025-01-12 16:36:33,497 - avg_ep_EM:0.8319
2025-01-12 16:36:33,497 - avg_ep_acc:0.9204
2025-01-12 16:36:33,497 - lr: 0.002865
2025-01-12 16:36:33,497 - Fin:Sun Jan 12 17:09:04 2025
2025-01-12 16:36:33,497 - ----------
2025-01-12 16:37:42,986 - Epoch: 9
2025-01-12 16:37:42,986 - Iter: 2500/ 5200
2025-01-12 16:37:42,986 - Loss:0.1273
2025-01-12 16:37:42,986 - avg_ep_EM:0.8347
2025-01-12 16:37:42,986 - avg_ep_acc:0.9222
2025-01-12 16:37:42,986 - lr: 0.002773
2025-01-12 16:37:42,986 - Fin:Sun Jan 12 17:09:04 2025
2025-01-12 16:37:42,986 - ----------
2025-01-12 16:38:52,474 - Epoch: 9
2025-01-12 16:38:52,474 - Iter: 2600/ 5200
2025-01-12 16:38:52,474 - Loss:0.1258
2025-01-12 16:38:52,474 - avg_ep_EM:0.8327
2025-01-12 16:38:52,474 - avg_ep_acc:0.9219
2025-01-12 16:38:52,474 - lr: 0.002680
2025-01-12 16:38:52,474 - Fin:Sun Jan 12 17:09:03 2025
2025-01-12 16:38:52,474 - ----------
2025-01-12 16:38:52,623 - Gama of progressive dropout attention is: 0.81707281
2025-01-12 16:40:03,679 - Epoch:10
2025-01-12 16:40:03,679 - Iter: 2700/ 5200
2025-01-12 16:40:03,679 - Loss:0.1226
2025-01-12 16:40:03,679 - avg_ep_EM:0.8401
2025-01-12 16:40:03,679 - avg_ep_acc:0.9255
2025-01-12 16:40:03,679 - lr: 0.002587
2025-01-12 16:40:03,679 - Fin:Sun Jan 12 17:09:06 2025
2025-01-12 16:40:03,679 - ----------
2025-01-12 16:41:13,247 - Epoch:10
2025-01-12 16:41:13,247 - Iter: 2800/ 5200
2025-01-12 16:41:13,247 - Loss:0.1243
2025-01-12 16:41:13,247 - avg_ep_EM:0.8362
2025-01-12 16:41:13,247 - avg_ep_acc:0.9235
2025-01-12 16:41:13,247 - lr: 0.002494
2025-01-12 16:41:13,247 - Fin:Sun Jan 12 17:09:06 2025
2025-01-12 16:41:13,247 - ----------
2025-01-12 16:41:55,077 - Gama of progressive dropout attention is: 0.80073135
2025-01-12 16:42:24,693 - Epoch:11
2025-01-12 16:42:24,693 - Iter: 2900/ 5200
2025-01-12 16:42:24,693 - Loss:0.1254
2025-01-12 16:42:24,693 - avg_ep_EM:0.8359
2025-01-12 16:42:24,693 - avg_ep_acc:0.9240
2025-01-12 16:42:24,693 - lr: 0.002400
2025-01-12 16:42:24,693 - Fin:Sun Jan 12 17:09:09 2025
2025-01-12 16:42:24,693 - ----------
2025-01-12 16:43:34,399 - Epoch:11
2025-01-12 16:43:34,400 - Iter: 3000/ 5200
2025-01-12 16:43:34,400 - Loss:0.1208
2025-01-12 16:43:34,400 - avg_ep_EM:0.8394
2025-01-12 16:43:34,400 - avg_ep_acc:0.9256
2025-01-12 16:43:34,400 - lr: 0.002306
2025-01-12 16:43:34,400 - Fin:Sun Jan 12 17:09:09 2025
2025-01-12 16:43:34,400 - ----------
2025-01-12 16:44:43,945 - Epoch:11
2025-01-12 16:44:43,945 - Iter: 3100/ 5200
2025-01-12 16:44:43,945 - Loss:0.1173
2025-01-12 16:44:43,945 - avg_ep_EM:0.8403
2025-01-12 16:44:43,945 - avg_ep_acc:0.9259
2025-01-12 16:44:43,945 - lr: 0.002212
2025-01-12 16:44:43,945 - Fin:Sun Jan 12 17:09:08 2025
2025-01-12 16:44:43,945 - ----------
2025-01-12 16:44:58,114 - Gama of progressive dropout attention is: 0.78471672
2025-01-12 16:45:55,960 - Epoch:12
2025-01-12 16:45:55,960 - Iter: 3200/ 5200
2025-01-12 16:45:55,960 - Loss:0.1223
2025-01-12 16:45:55,960 - avg_ep_EM:0.8335
2025-01-12 16:45:55,960 - avg_ep_acc:0.9232
2025-01-12 16:45:55,960 - lr: 0.002117
2025-01-12 16:45:55,960 - Fin:Sun Jan 12 17:09:12 2025
2025-01-12 16:45:55,960 - ----------
2025-01-12 16:47:05,524 - Epoch:12
2025-01-12 16:47:05,524 - Iter: 3300/ 5200
2025-01-12 16:47:05,524 - Loss:0.1160
2025-01-12 16:47:05,524 - avg_ep_EM:0.8402
2025-01-12 16:47:05,524 - avg_ep_acc:0.9259
2025-01-12 16:47:05,524 - lr: 0.002021
2025-01-12 16:47:05,524 - Fin:Sun Jan 12 17:09:12 2025
2025-01-12 16:47:05,524 - ----------
2025-01-12 16:48:01,462 - Gama of progressive dropout attention is: 0.76902239
2025-01-12 16:48:17,152 - Epoch:13
2025-01-12 16:48:17,152 - Iter: 3400/ 5200
2025-01-12 16:48:17,152 - Loss:0.1176
2025-01-12 16:48:17,152 - avg_ep_EM:0.8471
2025-01-12 16:48:17,152 - avg_ep_acc:0.9286
2025-01-12 16:48:17,152 - lr: 0.001925
2025-01-12 16:48:17,152 - Fin:Sun Jan 12 17:09:14 2025
2025-01-12 16:48:17,152 - ----------
2025-01-12 16:49:26,992 - Epoch:13
2025-01-12 16:49:26,993 - Iter: 3500/ 5200
2025-01-12 16:49:26,993 - Loss:0.1169
2025-01-12 16:49:26,993 - avg_ep_EM:0.8413
2025-01-12 16:49:26,993 - avg_ep_acc:0.9265
2025-01-12 16:49:26,993 - lr: 0.001829
2025-01-12 16:49:26,993 - Fin:Sun Jan 12 17:09:14 2025
2025-01-12 16:49:26,993 - ----------
2025-01-12 16:50:36,701 - Epoch:13
2025-01-12 16:50:36,701 - Iter: 3600/ 5200
2025-01-12 16:50:36,702 - Loss:0.1174
2025-01-12 16:50:36,702 - avg_ep_EM:0.8413
2025-01-12 16:50:36,702 - avg_ep_acc:0.9262
2025-01-12 16:50:36,702 - lr: 0.001732
2025-01-12 16:50:36,702 - Fin:Sun Jan 12 17:09:14 2025
2025-01-12 16:50:36,702 - ----------
2025-01-12 16:51:04,901 - Gama of progressive dropout attention is: 0.75364194
2025-01-12 16:51:48,964 - Epoch:14
2025-01-12 16:51:48,964 - Iter: 3700/ 5200
2025-01-12 16:51:48,964 - Loss:0.1164
2025-01-12 16:51:48,964 - avg_ep_EM:0.8552
2025-01-12 16:51:48,964 - avg_ep_acc:0.9320
2025-01-12 16:51:48,964 - lr: 0.001634
2025-01-12 16:51:48,964 - Fin:Sun Jan 12 17:09:18 2025
2025-01-12 16:51:48,964 - ----------
2025-01-12 16:52:58,627 - Epoch:14
2025-01-12 16:52:58,627 - Iter: 3800/ 5200
2025-01-12 16:52:58,627 - Loss:0.1165
2025-01-12 16:52:58,627 - avg_ep_EM:0.8443
2025-01-12 16:52:58,627 - avg_ep_acc:0.9271
2025-01-12 16:52:58,627 - lr: 0.001536
2025-01-12 16:52:58,627 - Fin:Sun Jan 12 17:09:17 2025
2025-01-12 16:52:58,627 - ----------
2025-01-12 16:54:08,295 - Epoch:14
2025-01-12 16:54:08,295 - Iter: 3900/ 5200
2025-01-12 16:54:08,295 - Loss:0.1139
2025-01-12 16:54:08,295 - avg_ep_EM:0.8456
2025-01-12 16:54:08,295 - avg_ep_acc:0.9280
2025-01-12 16:54:08,295 - lr: 0.001437
2025-01-12 16:54:08,295 - Fin:Sun Jan 12 17:09:17 2025
2025-01-12 16:54:08,295 - ----------
2025-01-12 16:54:08,462 - Gama of progressive dropout attention is: 0.73856910
2025-01-12 16:55:20,328 - Epoch:15
2025-01-12 16:55:20,328 - Iter: 4000/ 5200
2025-01-12 16:55:20,328 - Loss:0.1125
2025-01-12 16:55:20,328 - avg_ep_EM:0.8472
2025-01-12 16:55:20,328 - avg_ep_acc:0.9288
2025-01-12 16:55:20,328 - lr: 0.001337
2025-01-12 16:55:20,329 - Fin:Sun Jan 12 17:09:20 2025
2025-01-12 16:55:20,329 - ----------
2025-01-12 16:56:30,041 - Epoch:15
2025-01-12 16:56:30,041 - Iter: 4100/ 5200
2025-01-12 16:56:30,041 - Loss:0.1114
2025-01-12 16:56:30,041 - avg_ep_EM:0.8509
2025-01-12 16:56:30,041 - avg_ep_acc:0.9306
2025-01-12 16:56:30,041 - lr: 0.001236
2025-01-12 16:56:30,041 - Fin:Sun Jan 12 17:09:19 2025
2025-01-12 16:56:30,041 - ----------
2025-01-12 16:57:11,961 - Gama of progressive dropout attention is: 0.72379772
2025-01-12 16:57:42,101 - Epoch:16
2025-01-12 16:57:42,101 - Iter: 4200/ 5200
2025-01-12 16:57:42,101 - Loss:0.1108
2025-01-12 16:57:42,101 - avg_ep_EM:0.8534
2025-01-12 16:57:42,101 - avg_ep_acc:0.9320
2025-01-12 16:57:42,101 - lr: 0.001135
2025-01-12 16:57:42,101 - Fin:Sun Jan 12 17:09:22 2025
2025-01-12 16:57:42,101 - ----------
2025-01-12 16:58:51,686 - Epoch:16
2025-01-12 16:58:51,686 - Iter: 4300/ 5200
2025-01-12 16:58:51,686 - Loss:0.1134
2025-01-12 16:58:51,686 - avg_ep_EM:0.8483
2025-01-12 16:58:51,686 - avg_ep_acc:0.9296
2025-01-12 16:58:51,686 - lr: 0.001032
2025-01-12 16:58:51,686 - Fin:Sun Jan 12 17:09:21 2025
2025-01-12 16:58:51,686 - ----------
2025-01-12 17:00:01,109 - Epoch:16
2025-01-12 17:00:01,110 - Iter: 4400/ 5200
2025-01-12 17:00:01,110 - Loss:0.1157
2025-01-12 17:00:01,110 - avg_ep_EM:0.8470
2025-01-12 17:00:01,110 - avg_ep_acc:0.9289
2025-01-12 17:00:01,110 - lr: 0.000929
2025-01-12 17:00:01,110 - Fin:Sun Jan 12 17:09:21 2025
2025-01-12 17:00:01,110 - ----------
2025-01-12 17:00:15,182 - Gama of progressive dropout attention is: 0.70932177
2025-01-12 17:01:12,839 - Epoch:17
2025-01-12 17:01:12,839 - Iter: 4500/ 5200
2025-01-12 17:01:12,839 - Loss:0.1103
2025-01-12 17:01:12,839 - avg_ep_EM:0.8494
2025-01-12 17:01:12,839 - avg_ep_acc:0.9304
2025-01-12 17:01:12,839 - lr: 0.000824
2025-01-12 17:01:12,839 - Fin:Sun Jan 12 17:09:23 2025
2025-01-12 17:01:12,839 - ----------
2025-01-12 17:02:22,541 - Epoch:17
2025-01-12 17:02:22,541 - Iter: 4600/ 5200
2025-01-12 17:02:22,541 - Loss:0.1130
2025-01-12 17:02:22,541 - avg_ep_EM:0.8513
2025-01-12 17:02:22,541 - avg_ep_acc:0.9311
2025-01-12 17:02:22,541 - lr: 0.000717
2025-01-12 17:02:22,542 - Fin:Sun Jan 12 17:09:22 2025
2025-01-12 17:02:22,542 - ----------
2025-01-12 17:03:18,326 - Gama of progressive dropout attention is: 0.69513533
2025-01-12 17:03:34,385 - Epoch:18
2025-01-12 17:03:34,386 - Iter: 4700/ 5200
2025-01-12 17:03:34,386 - Loss:0.1064
2025-01-12 17:03:34,386 - avg_ep_EM:0.8559
2025-01-12 17:03:34,386 - avg_ep_acc:0.9332
2025-01-12 17:03:34,386 - lr: 0.000609
2025-01-12 17:03:34,386 - Fin:Sun Jan 12 17:09:24 2025
2025-01-12 17:03:34,386 - ----------
2025-01-12 17:04:43,974 - Epoch:18
2025-01-12 17:04:43,974 - Iter: 4800/ 5200
2025-01-12 17:04:43,974 - Loss:0.1117
2025-01-12 17:04:43,974 - avg_ep_EM:0.8550
2025-01-12 17:04:43,974 - avg_ep_acc:0.9329
2025-01-12 17:04:43,974 - lr: 0.000498
2025-01-12 17:04:43,974 - Fin:Sun Jan 12 17:09:24 2025
2025-01-12 17:04:43,974 - ----------
2025-01-12 17:05:53,803 - Epoch:18
2025-01-12 17:05:53,804 - Iter: 4900/ 5200
2025-01-12 17:05:53,804 - Loss:0.1101
2025-01-12 17:05:53,804 - avg_ep_EM:0.8533
2025-01-12 17:05:53,804 - avg_ep_acc:0.9320
2025-01-12 17:05:53,804 - lr: 0.000385
2025-01-12 17:05:53,804 - Fin:Sun Jan 12 17:09:23 2025
2025-01-12 17:05:53,804 - ----------
2025-01-12 17:06:21,790 - Gama of progressive dropout attention is: 0.68123262
2025-01-12 17:07:05,682 - Epoch:19
2025-01-12 17:07:05,682 - Iter: 5000/ 5200
2025-01-12 17:07:05,682 - Loss:0.1106
2025-01-12 17:07:05,682 - avg_ep_EM:0.8576
2025-01-12 17:07:05,682 - avg_ep_acc:0.9339
2025-01-12 17:07:05,682 - lr: 0.000268
2025-01-12 17:07:05,682 - Fin:Sun Jan 12 17:09:25 2025
2025-01-12 17:07:05,682 - ----------
2025-01-12 17:08:15,371 - Epoch:19
2025-01-12 17:08:15,371 - Iter: 5100/ 5200
2025-01-12 17:08:15,371 - Loss:0.1117
2025-01-12 17:08:15,371 - avg_ep_EM:0.8563
2025-01-12 17:08:15,371 - avg_ep_acc:0.9334
2025-01-12 17:08:15,371 - lr: 0.000144
2025-01-12 17:08:15,372 - Fin:Sun Jan 12 17:09:25 2025
2025-01-12 17:08:15,372 - ----------
2025-01-12 17:09:25,041 - Epoch:19
2025-01-12 17:09:25,042 - Iter: 5200/ 5200
2025-01-12 17:09:25,042 - Loss:0.1069
2025-01-12 17:09:25,042 - avg_ep_EM:0.8552
2025-01-12 17:09:25,042 - avg_ep_acc:0.9327
2025-01-12 17:09:25,042 - lr: 0.000002
2025-01-12 17:09:25,042 - Fin:Sun Jan 12 17:09:25 2025
2025-01-12 17:09:25,042 - ----------
2025-01-12 17:09:25,210 - Gama of progressive dropout attention is: 0.66760797
2025-01-12 17:09:28,286 - 0
2025-01-12 17:09:32,644 - 100
2025-01-12 17:09:36,925 - 200
2025-01-12 17:09:41,228 - 300
2025-01-12 17:09:41,816 - ===== Evaluation Scores =====
2025-01-12 17:09:41,816 - Pixel Accuracy: 0.8442
2025-01-12 17:09:41,816 - Mean Accuracy: 0.8523
2025-01-12 17:09:41,816 - Frequency Weighted IoU: 0.7321
2025-01-12 17:09:41,816 - Mean IoU: 0.7476
2025-01-12 17:09:41,816 - ===== Class IoU =====
2025-01-12 17:09:41,816 - Class 0: 0.7524
2025-01-12 17:09:41,817 - Class 1: 0.8142
2025-01-12 17:09:41,817 - Class 2: 0.7305
2025-01-12 17:09:41,817 - Class 3: 0.6931
